# Setting up AnythingLLM

This is a short guide to set up [AnythingLLM](https://anythingllm.com) on your desktop.

## Installing on desktop

Choose the appropriate version for your operating system:

[Download AnythingLLM](https://anythingllm.com/download)

> **Note:** On Windows, there is a warning when downloading that it's a potentially dangerous file and it's prevented from saving. Do it anyway :).

### Installation & configuration

Run the installer.  
Wait for a looooong time :)

When finished, start the app. You will be greeted with a welcome screen. Click on **Get started** to proceed.

![AnythingLLM LLM Preference Screenshot](/media/AnythingLLM%20Start%20Install%20Built%20In.jpg)

On the LLM Preference screen, choose your desired provider. Follow the specific instructions for the provider you chose:
- [Groq](groq.md)
- [AnythingLLM](builtin.md) (Buit in [Ollama](https://ollama.com/))

Read the Data Handling & Privacy statement and click on the right arrow again.

You can skip the survey, or you can fill it out if you want to help improve the app.

In the next step you will create your first workspace. Give it a name and click on the right arrow.

![AnythingLLM Workspace Screenshot](/media/AnythingLLM%20Create%20Workspace.jpg)

Click on the right arrow to proceed to the next step.
This will take you to the main screen of the app. On the first run there will be a welcome message with some useful information. Read it.

![AnythingLLM Welcome Screenshot](/media/AnythingLLM%20Welcome.jpg)

Click on the workspace you just created. This will take you to the workspace screen and you can start chatting!

![AnythingLLM Workspace Chat Screenshot](/media/AnythingLLM%20Chat.jpg)

> If you chose the built in provider, at this point when attemting to chat, you will see an error response:  
> `Ollama call failed with status code 400: model is required`.  
> 
> Please [download a model](/builtin_models.md).

Enjoy!